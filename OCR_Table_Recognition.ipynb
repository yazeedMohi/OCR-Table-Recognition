{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR Table Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1ouUvZDbZRprSQpHBXH_S8mLDrQ9U9Xve",
      "authorship_tag": "ABX9TyMYRzhcIoLTZtaZX78SXtD3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yazeedMohi/OCR-Table-Recognition/blob/main/OCR_Table_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3_awSso43XQ"
      },
      "source": [
        "# **Prerequisites**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dp6gm8asMp6"
      },
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install xlsxwriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hvoF5iF4809"
      },
      "source": [
        "# **Run Here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWrQQa_iyROr",
        "outputId": "959bd5e0-1558-4ced-cf01-3efa4dc324c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#RecPDF(\"/content/drive/My Drive/mech 0001.pdf\")\n",
        "RecImg(path = \"/content/drive/My Drive/Scan_0009.jpg\", excel_path = \"/content/test.xlsx\")"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PASS\n",
            "Excel file successfully created, saved at  /content/test.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlLuT0ds0Ale"
      },
      "source": [
        "# **Configuration**\n",
        "\n",
        "\n",
        "**excel_engine:** the engine to use when writing the excel file\n",
        "\n",
        "**ocr:** whether or not to use OCR and recognize the image\n",
        "\n",
        "**kernel_factor:** define how large is the detection edge kernel compared to the image width\n",
        "\n",
        "**morph_kernel:** define the size of the morphing kernel\n",
        "\n",
        "**kernel_factor_clean:** kernel factor used for cleaning the image\n",
        "\n",
        "**morph_kernel_clean:** morph kernel size for cleaning the image\n",
        "\n",
        "**adaptive_filter:** define whether to use adaptive filtering for thresholding or not\n",
        "\n",
        "**show_progress:** define whether to show images of the different stages or not\n",
        "\n",
        "**min_width, max_width:** acceptable range for box width\n",
        "\n",
        "**min_height, max_height:** acceptable range for box height\n",
        "\n",
        "**threshold:** whether or not to apply thresholding before recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWqnvUBU0DkA"
      },
      "source": [
        "class config:\n",
        "  def __init__(self):\n",
        "    self.show_progress = True\n",
        "    self.excel_engine=\"xlsxwriter\"\n",
        "    self.ocr=True \n",
        "    self.kernel_factor=200 \n",
        "    self.morph_kernel=3\n",
        "    self.kernel_factor_clean=120\n",
        "    self.morph_kernel_clean=1\n",
        "    self.adaptive_filter = False \n",
        "    self.show_progress = False \n",
        "    self.min_width = 15\n",
        "    self.max_width = 1000 \n",
        "    self.min_height=18\n",
        "    self.max_height = 50\n",
        "    self.excel_path = \"/content/test.xlsx\"\n",
        "    self.threshold = False\n",
        "conf = config()"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIwNe2Pdxro-"
      },
      "source": [
        "# **RecPDF**\n",
        "Recognizes each image in a PDF file, processes them one by one.\n",
        "\n",
        "**path:** path to the PDF file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ8ywbX3yNsy"
      },
      "source": [
        "import sys\n",
        "\n",
        "def RecPDF(path=\"\"):\n",
        "  with open(path, \"rb\") as file:\n",
        "      pdf = file.read()\n",
        "\n",
        "  img_counter = 0\n",
        "  pointer = 0\n",
        "  while True:\n",
        "      pointer = pdf.find(b\"stream\", pointer)\n",
        "      if pointer < 0:\n",
        "          break\n",
        "\n",
        "      x = pdf.find(b\"\\xff\\xd8\", pointer)\n",
        "      if x < 0:\n",
        "          pointer = pointer + 1\n",
        "          continue\n",
        "      else:\n",
        "          extension = \"jpg\"\n",
        "\n",
        "      limit = pdf.find(b\"endstream\", pointer)\n",
        "      if limit < 0:\n",
        "          break\n",
        "\n",
        "      y = pdf.find(b\"\\xff\\xd9\", pointer, limit) + 2\n",
        "\n",
        "      pointer = limit + 9\n",
        "      if y < 2:\n",
        "          continue        \n",
        "      \n",
        "      img = pdf[x:y]\n",
        "\n",
        "      img_counter = img_counter + 1\n",
        "\n",
        "      img_path = \"img_\" + str(img_counter) + \".\" + extension\n",
        "\n",
        "      with open(img_path, \"wb\") as jpgfile:\n",
        "          jpgfile.write(img)\n",
        "\n",
        "      RecImg(img_path, ocr=False, kernel_factor=260, morph_kernel=4, min_width =10, min_height=10)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMznfcYz3b_G"
      },
      "source": [
        "#**RecImg**\n",
        "Recognizes a table in image form, converts it to an Excel file.\n",
        "\n",
        "**path:** path to the input image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2mVSg9NvVGu"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image\n",
        "import pytesseract\n",
        "\n",
        "def RecImg(path=\"/content/sample.PNG\", excel_path = \"/content/test.xlsx\"):\n",
        "  #read your file\n",
        "  file= path\n",
        "  img = cv2.imread(file,0)\n",
        "\n",
        "  if(conf.show_progress):\n",
        "    print(\"ORIGINAL IMAGE\")\n",
        "    plotting = plt.imshow(img, cmap=\"gray\")\n",
        "    plt.show()\n",
        "\n",
        "  if(conf.adaptive_filter):\n",
        "    img_bin = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
        "  else:\n",
        "    thresh,img_bin = cv2.threshold(img,128,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU) \n",
        "  img_bin = 255-img_bin\n",
        "  \n",
        "  table = Cut_Table(img_bin, orig_img = img)\n",
        "  \n",
        "  if(conf.adaptive_filter):\n",
        "    table_bin = cv2.adaptiveThreshold(table,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
        "  else:\n",
        "    thresh,table_bin = cv2.threshold(table,128,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU) \n",
        "  table_bin = 255-table_bin\n",
        "\n",
        "  clean_table = Clean_Image(table, table_bin)\n",
        "\n",
        "  conts = Find_Contours(table_bin)\n",
        "  boxes = Arrange_Boxes(table, contours =conts)\n",
        "  \n",
        "  if(conf.ocr):\n",
        "    results = OCR_Boxes(clean_table, boxes)\n",
        "    Save_Excel(results, excel_path)"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-BHcEPnzUbo"
      },
      "source": [
        "# **Utility Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmEvgWJAya6J"
      },
      "source": [
        "## **Cut Table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4BMxTQ7sCN0"
      },
      "source": [
        "def Cut_Table(img, orig_img = None):\n",
        "  img_vh = Find_Lines(img, conf.kernel_factor, conf.morph_kernel)\n",
        "  def find_largest_cont(in_img):\n",
        "    cnts, _ = cv2.findContours(in_img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:10]\n",
        "    table = None\n",
        "    i = 0\n",
        "    for c in cnts:\n",
        "      # approximate the contour\n",
        "      peri = cv2.arcLength(c, True)\n",
        "      approx = cv2.approxPolyDP(c, 0.015 * peri, True)\n",
        "\n",
        "      if len(approx) == 4 and i>0:\n",
        "        table = approx\n",
        "        break\n",
        "      else: print(\"PASS\")\n",
        "      i +=1\n",
        "    return table\n",
        "  \n",
        "  largest_cont = find_largest_cont(img_vh)\n",
        "\n",
        "  def crop_minAreaRect(img, screenCnt):\n",
        "    pts = screenCnt.reshape(4, 2)\n",
        "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
        "\n",
        "    s = pts.sum(axis = 1)\n",
        "    rect[0] = pts[np.argmin(s)]\n",
        "    rect[2] = pts[np.argmax(s)]\n",
        "\n",
        "    diff = np.diff(pts, axis = 1)\n",
        "    rect[1] = pts[np.argmin(diff)]\n",
        "    rect[3] = pts[np.argmax(diff)]\n",
        "    # multiply the rectangle by the original ratio\n",
        "    #rect *= ratio\n",
        "\n",
        "    (tl, tr, br, bl) = rect\n",
        "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
        "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
        "\n",
        "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
        "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
        "\n",
        "    maxWidth = max(int(widthA), int(widthB))\n",
        "    maxHeight = max(int(heightA), int(heightB))\n",
        "\n",
        "    dst = np.array([\n",
        "      [0, 0],\n",
        "      [maxWidth - 1, 0],\n",
        "      [maxWidth - 1, maxHeight - 1],\n",
        "      [0, maxHeight - 1]], dtype = \"float32\")\n",
        "\n",
        "    M = cv2.getPerspectiveTransform(rect, dst)\n",
        "    warp = cv2.warpPerspective(img, M, (maxWidth, maxHeight))\n",
        "    return warp\n",
        "  table_img = crop_minAreaRect(orig_img, largest_cont)\n",
        "  if(conf.show_progress):\n",
        "    print(\"CROPPED TABLE\")\n",
        "    plotting = plt.imshow(table_img,cmap='gray')\n",
        "    plt.show()\n",
        "  return table_img"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qoSLSg5yiVv"
      },
      "source": [
        "## **Find Contours**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2siX6zhrJa6"
      },
      "source": [
        "def Find_Contours(img):\n",
        "  img_vh = Find_Lines(img, conf.kernel_factor, conf.morph_kernel)\n",
        "  contours, hierarchy = cv2.findContours(img_vh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  return contours"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhMZmx9lylIT"
      },
      "source": [
        "## **Find Lines**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ1MCFBTqfAY"
      },
      "source": [
        "def Find_Lines(img_bin, kernel_factor = 300, morph_kernel=1):\n",
        "  # countcol(width) of kernel as 100th of total width\n",
        "  kernel_len = np.array(img_bin).shape[1]//kernel_factor\n",
        "  # Defining a vertical kernel to detect all vertical lines of image \n",
        "  ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_len))\n",
        "  # Defining a horizontal kernel to detect all horizontal lines of image\n",
        "  hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_len, 1))\n",
        "  # A kernel of 2x2\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (morph_kernel, morph_kernel))\n",
        "\n",
        "  #Use vertical kernel to detect and save the vertical lines in a jpg\n",
        "  image_1 = cv2.erode(img_bin, ver_kernel, iterations=3)\n",
        "  vertical_lines = cv2.dilate(image_1, ver_kernel, iterations=3)\n",
        "\n",
        "  #Use horizontal kernel to detect and save the horizontal lines in a jpg\n",
        "  image_2 = cv2.erode(img_bin, hor_kernel, iterations=3)\n",
        "  horizontal_lines = cv2.dilate(image_2, hor_kernel, iterations=3)\n",
        "\n",
        "  # Combine horizontal and vertical lines in a new third image, with both having same weight.\n",
        "  img_vh = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0.0)\n",
        "  #Eroding and thesholding the image\n",
        "  img_vh = cv2.erode(~img_vh, kernel, iterations=2)\n",
        "  if(conf.adaptive_filter):\n",
        "    img_vh = cv2.adaptiveThreshold(img_vh,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
        "  else:\n",
        "    thresh, img_vh = cv2.threshold(img_vh,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "  \n",
        "  return img_vh"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDOtRHE2yoHr"
      },
      "source": [
        "## **Clean Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwSoA9-PqQ8m"
      },
      "source": [
        "def Clean_Image(img, img_bin):\n",
        "  if(conf.threshold):\n",
        "    thresh, my_img = cv2.threshold(my_img,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)   \n",
        "  else:\n",
        "    my_img = img\n",
        "  \n",
        "  img_vh = Find_Lines(img_bin, kernel_factor = conf.kernel_factor_clean, morph_kernel = conf.morph_kernel_clean)\n",
        "\n",
        "  bitxor = cv2.bitwise_xor(my_img,img_vh)\n",
        "  bitnot = cv2.bitwise_not(bitxor)\n",
        "  \n",
        "  if(conf.show_progress):\n",
        "    print(\"CLEAN IMAGE\")\n",
        "    plotting = plt.imshow(bitnot,cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "  return bitnot"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJvze67Ayrbx"
      },
      "source": [
        "## **Arrange Boxes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spXJDSS1pzI8"
      },
      "source": [
        "def Arrange_Boxes(img, contours = None):\n",
        "\n",
        "  def sort_contours(cnts, method=\"left-to-right\"):\n",
        "      # initialize the reverse flag and sort index\n",
        "      reverse = False\n",
        "      i = 0\n",
        "      # handle if we need to sort in reverse\n",
        "      if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
        "          reverse = True\n",
        "      # handle if we are sorting against the y-coordinate rather than\n",
        "      # the x-coordinate of the bounding box\n",
        "      if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
        "          i = 1\n",
        "      # construct the list of bounding boxes and sort them from top to\n",
        "      # bottom\n",
        "      boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
        "      (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
        "      key=lambda b:b[1][i], reverse=reverse))\n",
        "      # return the list of sorted contours and bounding boxes\n",
        "      return (cnts, boundingBoxes)\n",
        "\n",
        "  # Sort all the contours by top to bottom.\n",
        "  contours, boundingBoxes = sort_contours(contours, method=\"top-to-bottom\")\n",
        "\n",
        "  #Creating a list of heights for all detected boxes\n",
        "  heights = [boundingBoxes[i][3] for i in range(len(boundingBoxes))]\n",
        "\n",
        "  #Get mean of heights\n",
        "  mean = np.mean(heights)\n",
        "\n",
        "  #Create list box to store all boxes in  \n",
        "  box = []\n",
        "  # Get position (x,y), width and height for every contour and show the contour on image\n",
        "  for c in contours:\n",
        "      x, y, w, h = cv2.boundingRect(c)\n",
        "      if (w<conf.max_width and h<conf.max_height and w>conf.min_width and h>conf.min_height):\n",
        "          image = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "          box.append([x,y,w,h])\n",
        "          \n",
        "\n",
        "  if(conf.show_progress):      \n",
        "    print(\"EXTRACTED BOXES\")  \n",
        "    plotting = plt.imshow(image,cmap='GnBu_r')\n",
        "    plt.show()\n",
        "  #Creating two lists to define row and column in which cell is located\n",
        "  row=[]\n",
        "  column=[]\n",
        "  j=0\n",
        "\n",
        "  #Sorting the boxes to their respective row and column\n",
        "  for i in range(len(box)):    \n",
        "          \n",
        "      if(i==0):\n",
        "          column.append(box[i])\n",
        "          previous=box[i]    \n",
        "      \n",
        "      else:\n",
        "          if(box[i][1]<=previous[1]+mean/2):\n",
        "              column.append(box[i])\n",
        "              previous=box[i]            \n",
        "              \n",
        "              if(i==len(box)-1):\n",
        "                  row.append(column)        \n",
        "              \n",
        "          else:\n",
        "              row.append(column)\n",
        "              column=[]\n",
        "              previous = box[i]\n",
        "              column.append(box[i])\n",
        "  \n",
        "  if(conf.show_progress):        \n",
        "    print(\"Table Size: \", len(row),\"X\",len(row[0]))\n",
        "  return row"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmndbB95yuFo"
      },
      "source": [
        "## **OCR Boxes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc0bkmH_or9O"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def OCR_Boxes(image,  boxes):\n",
        "  result = []\n",
        "  for i in range(len(boxes)):\n",
        "      result.append([])\n",
        "      for j in range(len(boxes[i])):\n",
        "          y,x,w,h = boxes[i][j][0],boxes[i][j][1], boxes[i][j][2],boxes[i][j][3]\n",
        "          finalimg = image[x:x+h, y:y+w]\n",
        "          kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
        "          border = cv2.copyMakeBorder(finalimg,2,2,2,2, cv2.BORDER_CONSTANT,value=[255,255])\n",
        "          resizing = cv2.resize(border, None, fx=5, fy=5, interpolation=cv2.INTER_CUBIC)\n",
        "          dilation = cv2.dilate(resizing, kernel,iterations=1)\n",
        "          erosion = cv2.erode(dilation, kernel,iterations=2)\n",
        "          \n",
        "          out = pytesseract.image_to_string(erosion)\n",
        "          if(len(out)==0):\n",
        "              out = pytesseract.image_to_string(erosion, config='-psm 3')\n",
        "          if(len(out)==0):\n",
        "              out = pytesseract.image_to_string(erosion, config='-psm 7')\n",
        "          out.strip(\"\\n\")\n",
        "          if(len(out)==0): out = \" \"\n",
        "          if(conf.show_progress):\n",
        "              plotting = plt.imshow(erosion,cmap='gray')\n",
        "              plt.show()\n",
        "              print(x,y,w,h,\" || \",out)\n",
        "          \n",
        "          result[i].append(out)\n",
        "  return result"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8--ngH4Lywuh"
      },
      "source": [
        "## **Save Excel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZFQ6l0CwsOT"
      },
      "source": [
        "def Save_Excel(result, save_path):\n",
        "  dataframe = pd.DataFrame(result)\n",
        "  data = dataframe.style.set_properties(align=\"left\")\n",
        "  data.to_excel(save_path, engine=conf.excel_engine)\n",
        "  print(\"Excel file successfully created, saved at \", save_path)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3d1523RC_7-"
      },
      "source": [
        "        \n",
        "  if(show_progress):          \n",
        "    print(len(column))\n",
        "    print(len(row))\n",
        "\n",
        "  #calculating maximum number of cells\n",
        "  max_countcol = 0\n",
        "  for i in range(len(row)):\n",
        "      countcol = len(row[i])\n",
        "      if countcol > max_countcol:\n",
        "          max_countcol = countcol\n",
        "\n",
        "  countcol = max_countcol\n",
        "\n",
        "  #Retrieving the center of each column\n",
        "  center = [int(row[i][j][0]+row[i][j][2]/2) for j in range(len(row[i])) if row[0]]\n",
        "\n",
        "  center=np.array(center)\n",
        "  center.sort()\n",
        "  #if(show_progress):\n",
        "  #  print(center)\n",
        "\n",
        "  #Regarding the distance to the columns center, the boxes are arranged in respective order\n",
        "\n",
        "  finalboxes = []\n",
        "  #my_max = 300000000\n",
        "  #how_many = 1\n",
        "  return\n",
        "  if(ocr):\n",
        "    #from every single image-based cell/box the strings are extracted via pytesseract and stored in a list\n",
        "    outer=[]\n",
        "    for i in range(len(finalboxes)):\n",
        "        for j in range(len(finalboxes[i])):\n",
        "            inner=''\n",
        "            if(len(finalboxes[i][j])==0):\n",
        "                outer.append(' ')\n",
        "            else:\n",
        "                for k in range(len(finalboxes[i][j])):\n",
        "                    y,x,w,h = finalboxes[i][j][k][0],finalboxes[i][j][k][1], finalboxes[i][j][k][2],finalboxes[i][j][k][3]\n",
        "                    finalimg = bitnot[x:x+h, y:y+w]\n",
        "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))\n",
        "                    border = cv2.copyMakeBorder(finalimg,2,2,2,2, cv2.BORDER_CONSTANT,value=[255,255])\n",
        "                    resizing = cv2.resize(border, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "                    dilation = cv2.dilate(resizing, kernel,iterations=1)\n",
        "                    erosion = cv2.erode(dilation, kernel,iterations=2)\n",
        "                    \n",
        "                    #out = pytesseract.image_to_string(erosion)\n",
        "                    #if(len(out)==0):\n",
        "                    out = pytesseract.image_to_string(erosion, config='--psm 3')\n",
        "                    if(show_progress):\n",
        "                      print(x,y,w,h,out)\n",
        "                    inner = inner +\" \"+ out\n",
        "                outer.append(inner)\n",
        "\n",
        "    #Creating a dataframe of the generated OCR list\n",
        "    arr = np.array(outer)\n",
        "    dataframe = pd.DataFrame(arr.reshape(len(row), countcol))\n",
        "    print(dataframe)\n",
        "    data = dataframe.style.set_properties(align=\"left\")\n",
        "    #Converting it in a excel-file\n",
        "    data.to_excel(\"/content/test.xlsx\", engine=excel_engine)\n",
        "\n",
        "    def Clean_Image(img, img_bin):\n",
        "  if(conf.threshold):\n",
        "    thresh, my_img = cv2.threshold(my_img,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)   \n",
        "  else:\n",
        "    my_img = img\n",
        "  \n",
        "  img_vh = Find_Lines(img_bin, kernel_factor = conf.kernel_factor_clean, morph_kernel = conf.morph_kernel_clean)\n",
        "\n",
        "  bitand = cv2.bitwise_and(my_img, cv2.bitwise_not(img_vh))\n",
        "  bitxor = cv2.bitwise_xor(cv2.bitwise_not(my_img), bitand)\n",
        "  bitnot = cv2.bitwise_not(bitxor)\n",
        "  \n",
        "  if(conf.show_progress):\n",
        "    print(\"AND IMAGE\")\n",
        "    plotting = plt.imshow(bitand,cmap='gray')\n",
        "    plt.show()\n",
        "    print(\"MY IMAGE\")\n",
        "    plotting = plt.imshow(cv2.bitwise_not(my_img),cmap='gray')\n",
        "    plt.show()\n",
        "    print(\"XOR IMAGE\")\n",
        "    plotting = plt.imshow(bitxor,cmap='gray')\n",
        "    plt.show()\n",
        "    print(\"CLEAN IMAGE\")\n",
        "    plotting = plt.imshow(bitnot,cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "  return bitnot"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
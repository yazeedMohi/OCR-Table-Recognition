{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR Table Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "p3_awSso43XQ",
        "9hvoF5iF4809",
        "xIwNe2Pdxro-",
        "iMznfcYz3b_G",
        "4qoSLSg5yiVv",
        "rhMZmx9lylIT",
        "hDOtRHE2yoHr",
        "bJvze67Ayrbx",
        "HmndbB95yuFo",
        "8--ngH4Lywuh"
      ],
      "toc_visible": true,
      "mount_file_id": "1ouUvZDbZRprSQpHBXH_S8mLDrQ9U9Xve",
      "authorship_tag": "ABX9TyPyJRHnpqrUfUFSZCsMtYOr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yazeedMohi/OCR-Table-Recognition/blob/main/OCR_Table_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3_awSso43XQ"
      },
      "source": [
        "# **Prerequisites**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dp6gm8asMp6",
        "outputId": "320dfbf6-6f10-4ee2-fc46-b38eda1f114d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt-get install tesseract-ocr-ara\n",
        "!pip install pytesseract\n",
        "!pip install xlsxwriter\n",
        "!pip install unidecode\n",
        "!pip install pymupdf"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr-ara is already the newest version (4.00~git24-0e00fe6-1.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.6/dist-packages (1.3.7)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Collecting pymupdf\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/75/442a1bcc89569453969f34a53000e8a80e3da13367e3e29b81b5137ef388/PyMuPDF-1.18.3-cp36-cp36m-manylinux2010_x86_64.whl (6.3MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3MB 3.9MB/s \n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.18.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hvoF5iF4809"
      },
      "source": [
        "# **Run Here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWrQQa_iyROr"
      },
      "source": [
        "from unidecode import unidecode\n",
        "import re\n",
        "#RecPDF(\"/content/drive/My Drive/mech 0001.pdf\")\n",
        "RecImg(path = \"/content/drive/My Drive/Scan_0021.jpg\", excel_path = \"/content/testB.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlLuT0ds0Ale"
      },
      "source": [
        "# **Configuration**\n",
        "\n",
        "\n",
        "**excel_engine:** the engine to use when writing the excel file\n",
        "\n",
        "**ocr:** whether or not to use OCR and recognize the image\n",
        "\n",
        "**kernel_factor:** define how large is the detection edge kernel compared to the image width\n",
        "\n",
        "**morph_kernel:** define the size of the morphing kernel\n",
        "\n",
        "**kernel_factor_clean:** kernel factor used for cleaning the image\n",
        "\n",
        "**morph_kernel_clean:** morph kernel size for cleaning the image\n",
        "\n",
        "**adaptive_filter:** define whether to use adaptive filtering for thresholding or not\n",
        "\n",
        "**show_progress:** define whether to show images of the different stages or not\n",
        "\n",
        "**min_width, max_width:** acceptable range for box width\n",
        "\n",
        "**min_height, max_height:** acceptable range for box height\n",
        "\n",
        "**threshold:** whether or not to apply thresholding before recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWqnvUBU0DkA"
      },
      "source": [
        "class config:\n",
        "  def __init__(self):\n",
        "    self.excel_engine=\"xlsxwriter\"\n",
        "    self.ocr=True \n",
        "    self.kernel_factor=200 \n",
        "    self.morph_kernel=3\n",
        "    self.kernel_factor_clean=120\n",
        "    self.morph_kernel_clean=1\n",
        "    self.adaptive_filter = False \n",
        "    self.show_progress = True\n",
        "    self.min_width = 20\n",
        "    self.max_width = 1000 \n",
        "    self.min_height=18\n",
        "    self.max_height = 250\n",
        "    self.passes = 1\n",
        "    self.threshold = False\n",
        "    self.ara_col = 3\n",
        "    self.ara_row = 1\n",
        "    self.last_rows = 5\n",
        "    self.rot_start = 4\n",
        "    self.rot_last = 1\n",
        "    self.header_arabic = True\n",
        "conf = config()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsRldXzPAC2D"
      },
      "source": [
        "# **GEN IMGS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE-im10MAIJW",
        "outputId": "8f38c106-abef-49fc-d21c-fd427b2a79a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "import fitz\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.backends.backend_pdf\n",
        "import matplotlib.font_manager as mfm\n",
        "\n",
        "\n",
        "dir_path = '/content/drive/MyDrive/FermaSorted'\n",
        "\n",
        "departmentsList = {\n",
        "    'a':'Agricultural', 'o':'Chemical', 'e':'Civil', 'u':'Electrical', \n",
        "    'h':'Mechanical', 't':'Surveying', 'n':'Mining', 's':'Petroleum' \n",
        "}\n",
        "\n",
        "grades = {'1st': 1, '2nd': 2, '3rd': 3, '4th': 4, '5th': 5}\n",
        "\n",
        "def put_pg_into_sortedscan(yr, gr, dept, pgno):\n",
        "    if not (yr in sortedscan):\n",
        "        sortedscan[yr] = {}\n",
        "        \n",
        "    if not (gr in sortedscan[yr]):\n",
        "        sortedscan[yr][gr] = {}\n",
        "        \n",
        "    if not (dept in sortedscan[yr][gr]):\n",
        "        sortedscan[yr][gr][dept] = [pgno];\n",
        "    else:\n",
        "        if not(pgno in sortedscan[yr][gr][dept]):\n",
        "            sortedscan[yr][gr][dept].append(pgno)\n",
        "\n",
        "def pix2np(pix):\n",
        "    im = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, pix.n)\n",
        "    im = np.ascontiguousarray(im[..., [2, 1, 0]])  # rgb to bgr\n",
        "    return im\n",
        "\n",
        "def border_around_subplots(sub1):\n",
        "    autoAxis = sub1.axis()\n",
        "    rec = plt.Rectangle(\n",
        "        (autoAxis[0]-0.7,\n",
        "        autoAxis[2]-0.2),\n",
        "        (autoAxis[1]-autoAxis[0])+1,\n",
        "        (autoAxis[3]-autoAxis[2])+0.4, fill=False, lw=2)\n",
        "    rec = sub1.add_patch(rec)\n",
        "    rec.set_clip_on(False)\n",
        "    plt.tight_layout()\n",
        "\n",
        "def FindImagesInPDF(path, yr, gr):\n",
        "    doc = fitz.open(path)\n",
        "    \n",
        "    year_str = str(yr);\n",
        "    gr_str = str(gr)\n",
        "    dept_data = sortedscan[year_str][gr_str];\n",
        "    \n",
        "    for dept in dept_data:\n",
        "        if(not (dept in departmentsList.values()) ):\n",
        "            continue\n",
        "        else:\n",
        "            for pgno in dept_data[dept]:\n",
        "                page = doc.loadPage(pgno)\n",
        "                imgs_in_page = doc.getPageImageList(pgno)\n",
        "                if(len(imgs_in_page) == 1):\n",
        "                    xref = imgs_in_page[0]\n",
        "                    pix = fitz.Pixmap(doc, xref[0])\n",
        "                else:\n",
        "                    pix = page.getPixmap(fitz.Matrix(1.0, 0, 0, 1.0, 0, 0))\n",
        "                \n",
        "                img = pix2np(pix)\n",
        "                \n",
        "                h, w, _ = img.shape\n",
        "                if(h > w):\n",
        "                    img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "                h, w, _ = img.shape\n",
        "                \n",
        "                imgx = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "                \n",
        "                cut_image = RecImg(img, None, None)\n",
        "                \n",
        "                fig, axs = plt.subplots(2, 1)\n",
        "                fig.set_size_inches(8, 10)\n",
        "                \n",
        "                axs[0].imshow(imgx, cmap='gray')\n",
        "                axs[0].set_title('Original: {}/{}-{}-{}-Page No {}'.format(yr, yr+1, gr, dept, pgno))\n",
        "                axs[0].set_xticks([]); axs[0].set_yticks([])\n",
        "                border_around_subplots(axs[0])\n",
        "                \n",
        "                if not (cut_image is None):\n",
        "                    axs[1].imshow(cut_image, cmap='gray')\n",
        "                    axs[1].set_title('Cut Table')\n",
        "                    axs[1].set_xticks([]); axs[1].set_yticks([])\n",
        "                    border_around_subplots(axs[1])\n",
        "                \n",
        "                pdf_debug.savefig()\n",
        "                plt.close()\n",
        "                \n",
        "                # print(\"W: \", w, \"H: \", h, \"W2: \", cut_image.shape[0], \"H2: \", cut_image.shape[1])\n",
        "                \n",
        "                # merged = np.concatenate((imgx, cut_image), axis=1)\n",
        "                # merged_s = cv2.resize(merged, (wn, hn), interpolation=cv2.INTER_CUBIC)\n",
        "                \n",
        "                # cv2.waitKey(0)\n",
        "    return\n",
        "\n",
        "if (os.stat('sortedscans.json').st_size == 0):\n",
        "    exit()\n",
        "    sortedscan = {}\n",
        "else:\n",
        "    with open('sortedscans.json', \"rb\") as f:\n",
        "        sortedscan = json.load(f)\n",
        "\n",
        "# print(json.dumps(sortedscan, indent=2))\n",
        "# exit()\n",
        "with matplotlib.backends.backend_pdf.PdfPages(\"output_debug.pdf\") as pdf_debug:\n",
        "    for entry in os.scandir(dir_path):\n",
        "        if(entry.is_file() and (entry.path.endswith(\".pdf\"))):\n",
        "            pass\n",
        "        else:\n",
        "            print(\"Found non pdf file ... Exiting\")\n",
        "            exit()\n",
        "            \n",
        "        currentFile = entry.path\n",
        "        sortedscan[\"lastFile\"] = currentFile\n",
        "        \n",
        "        print(entry.path)\n",
        "        \n",
        "        xst = entry.name.split('_')\n",
        "        if len(xst) == 3:\n",
        "            pass\n",
        "        elif len(xst) == 2:\n",
        "            yr = int(xst[0])\n",
        "            gr_k = xst[1].split('.')[0];\n",
        "            gr = grades[gr_k]\n",
        "            \n",
        "            # if(gr < 4): continue\n",
        "            # if(yr > 2013): break\n",
        "            \n",
        "            if( (str(yr) in sortedscan) and (str(gr) in sortedscan[str(yr)])):\n",
        "                print(\"Year: \", \"{}/{}\".format(yr, yr+1), \" Grade: \", gr_k);\n",
        "                FindImagesInPDF(entry.path, yr, gr)\n",
        "            else:\n",
        "                print(\"NOT IN DICTIONARY Year: \", \"{}/{}\".format(yr, yr+1), \" Grade: \", gr_k);\n",
        "        else:\n",
        "            pass\n",
        "        "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FermaSorted/2013_2nd.pdf\n",
            "Year:  2013/2014  Grade:  2nd\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2013_3rd.pdf\n",
            "Year:  2013/2014  Grade:  3rd\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2013_4th.pdf\n",
            "Year:  2013/2014  Grade:  4th\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2013_1st.pdf\n",
            "Year:  2013/2014  Grade:  1st\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2013_Sub_3rd.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2013_Sub_4th.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2013_Sub_1st.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2013_Sub_2nd.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2015_4th.pdf\n",
            "Year:  2015/2016  Grade:  4th\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mupdf: expected object number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2015_2nd.pdf\n",
            "Year:  2015/2016  Grade:  2nd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mupdf: expected object number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2015_1st.pdf\n",
            "NOT IN DICTIONARY Year:  2015/2016  Grade:  1st\n",
            "/content/drive/MyDrive/FermaSorted/2015_3rd.pdf\n",
            "Year:  2015/2016  Grade:  3rd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mupdf: expected object number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2015_Sub_3rd.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2015_Sub_4th.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2015_Sub_2nd.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2015_Sub_1st.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2014_Sub_3rd.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2014_Sub_4th.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2014_Sub_2nd.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2014_Sub_1st.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2014_2nd.pdf\n",
            "Year:  2014/2015  Grade:  2nd\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2014_3rd.pdf\n",
            "Year:  2014/2015  Grade:  3rd\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2014_4th.pdf\n",
            "Year:  2014/2015  Grade:  4th\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2016_2nd.pdf\n",
            "Year:  2016/2017  Grade:  2nd\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2016_3rd.pdf\n",
            "Year:  2016/2017  Grade:  3rd\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2014_1st.pdf\n",
            "NOT IN DICTIONARY Year:  2014/2015  Grade:  1st\n",
            "/content/drive/MyDrive/FermaSorted/2015_5th.pdf\n",
            "Year:  2015/2016  Grade:  5th\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2015_Sub_5th.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2016_4th.pdf\n",
            "Year:  2016/2017  Grade:  4th\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2016_5th.pdf\n",
            "Year:  2016/2017  Grade:  5th\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2016_Sub_5th.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2017_4th.pdf\n",
            "NOT IN DICTIONARY Year:  2017/2018  Grade:  4th\n",
            "/content/drive/MyDrive/FermaSorted/2017_5th.pdf\n",
            "NOT IN DICTIONARY Year:  2017/2018  Grade:  5th\n",
            "/content/drive/MyDrive/FermaSorted/2017_Sub_5th.pdf\n",
            "/content/drive/MyDrive/FermaSorted/2017_2nd.pdf\n",
            "Year:  2017/2018  Grade:  2nd\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "/content/drive/MyDrive/FermaSorted/2017_3rd.pdf\n",
            "Year:  2017/2018  Grade:  3rd\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n",
            "PASS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmbLOF0GBlBd",
        "outputId": "716673cd-95c8-48ab-fb3d-d656cc0c8061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from unidecode import unidecode\n",
        "import re\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.backends.backend_pdf\n",
        "import matplotlib.font_manager as mfm\n",
        "import csv\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "#from bidi.algorithm import get_display\n",
        "#import arabic_reshaper\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image\n",
        "import pytesseract\n",
        "\n",
        "fontname = mfm.findfont('Tahoma', fontext='ttf') \n",
        "\"\"\"reshaper = arabic_reshaper.ArabicReshaper(\n",
        "    arabic_reshaper.config_for_true_type_font(\n",
        "        fontname,\n",
        "        arabic_reshaper.ENABLE_NO_LIGATURES\n",
        "    )\n",
        ")\n",
        "\"\"\"\n",
        "class config:\n",
        "  def __init__(self):\n",
        "    self.excel_engine=\"xlsxwriter\"\n",
        "    self.ocr=True \n",
        "    self.kernel_factor=200 \n",
        "    self.morph_kernel=3\n",
        "    self.kernel_factor_clean=120\n",
        "    self.morph_kernel_clean=1\n",
        "    self.adaptive_filter = False \n",
        "    self.show_progress = True\n",
        "    self.min_width = 20\n",
        "    self.max_width = 1000 \n",
        "    self.min_height=18\n",
        "    self.max_height = 250\n",
        "    self.threshold = False\n",
        "    self.ara_col = 3\n",
        "    self.ara_row = 1\n",
        "    self.last_rows = 5\n",
        "    self.rot_start = 4\n",
        "    self.rot_last = 1\n",
        "    self.header_arabic = True\n",
        "conf = config()\n",
        "\n",
        "dpidef = 200\n",
        "\n",
        "def RecImg(imgs, excel_path, dbg_path=None):\n",
        "    if(len(imgs.shape) == 3):\n",
        "        height, width, channels = imgs.shape\n",
        "    else:\n",
        "        height, width = imgs.shape\n",
        "\n",
        "    if(height > width):\n",
        "        imgs = cv2.rotate(imgs, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "\n",
        "    img = cv2.cvtColor(imgs.copy(), cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    try:\n",
        "\n",
        "        if(conf.adaptive_filter):\n",
        "            img_bin = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
        "        else:\n",
        "            thresh,img_bin = cv2.threshold(img,128,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU) \n",
        "        img_bin = 255-img_bin\n",
        "\n",
        "        table = Cut_Table(img_bin, orig_img = img)\n",
        "        \n",
        "        return table\n",
        "\n",
        "        if(conf.adaptive_filter):\n",
        "            table_bin = cv2.adaptiveThreshold(table,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
        "        else:\n",
        "            thresh,table_bin = cv2.threshold(table,128,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU) \n",
        "        table_bin = 255-table_bin\n",
        "\n",
        "        clean_table = Clean_Image(table, table_bin)\n",
        "\n",
        "        conts = Find_Contours(table_bin)\n",
        "        boxes = Arrange_Boxes(table, contours =conts)\n",
        "        print(\"Dumping Boxes\")\n",
        "        if(conf.ocr):\n",
        "            # results = OCR_Boxes(clean_table, boxes)\n",
        "            DumpBoxes(clean_table, boxes)\n",
        "            # Save_Excel(results, excel_path)\n",
        "    except:\n",
        "        print('An Error has occured')\n",
        "        raise\n",
        "        \n",
        "def Cut_Table(img, orig_img = None):\n",
        "    img_vh = Find_Lines(img, conf.kernel_factor, conf.morph_kernel)\n",
        "    \n",
        "    def find_largest_cont(in_img):\n",
        "        cnts, _ = cv2.findContours(in_img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:10]\n",
        "        table = None\n",
        "        i = 0\n",
        "        for c in cnts:\n",
        "            # approximate the contour\n",
        "            peri = cv2.arcLength(c, True)\n",
        "            approx = cv2.approxPolyDP(c, 0.015 * peri, True)\n",
        "            \n",
        "            if len(approx) == 4 and i>0:\n",
        "                table = approx\n",
        "                break\n",
        "            else: \n",
        "                print(\"PASS\")\n",
        "                i +=1\n",
        "        \n",
        "        return table\n",
        "        \n",
        "    def crop_minAreaRect(img, screenCnt):\n",
        "        if (screenCnt is None): return None\n",
        "        pts = screenCnt.reshape(4, 2)\n",
        "        rect = np.zeros((4, 2), dtype = \"float32\")\n",
        "\n",
        "        s = pts.sum(axis = 1)\n",
        "        rect[0] = pts[np.argmin(s)]\n",
        "        rect[2] = pts[np.argmax(s)]\n",
        "\n",
        "        diff = np.diff(pts, axis = 1)\n",
        "        rect[1] = pts[np.argmin(diff)]\n",
        "        rect[3] = pts[np.argmax(diff)]\n",
        "        # multiply the rectangle by the original ratio\n",
        "        #rect *= ratio\n",
        "\n",
        "        (tl, tr, br, bl) = rect\n",
        "        widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
        "        widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
        "\n",
        "        heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
        "        heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
        "\n",
        "        maxWidth = max(int(widthA), int(widthB))\n",
        "        maxHeight = max(int(heightA), int(heightB))\n",
        "\n",
        "        dst = np.array([\n",
        "          [0, 0],\n",
        "          [maxWidth - 1, 0],\n",
        "          [maxWidth - 1, maxHeight - 1],\n",
        "          [0, maxHeight - 1]], dtype = \"float32\")\n",
        "\n",
        "        M = cv2.getPerspectiveTransform(rect, dst)\n",
        "        warp = cv2.warpPerspective(img, M, (maxWidth, maxHeight))\n",
        "        return warp\n",
        "  \n",
        "    largest_cont = find_largest_cont(img_vh)\n",
        "    table_img = crop_minAreaRect(orig_img, largest_cont)\n",
        "    \n",
        "    return table_img\n",
        "\n",
        "def Find_Contours(img):\n",
        "  img_vh = Find_Lines(img, conf.kernel_factor, conf.morph_kernel)\n",
        "  contours, hierarchy = cv2.findContours(img_vh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  return contours\n",
        "\n",
        "def Find_Lines(img_bin, kernel_factor = 300, morph_kernel=1):\n",
        "  # countcol(width) of kernel as 100th of total width\n",
        "  kernel_len = np.array(img_bin).shape[1]//kernel_factor\n",
        "  # Defining a vertical kernel to detect all vertical lines of image \n",
        "  ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_len))\n",
        "  # Defining a horizontal kernel to detect all horizontal lines of image\n",
        "  hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_len, 1))\n",
        "  # A kernel of 2x2\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (morph_kernel, morph_kernel))\n",
        "\n",
        "  #Use vertical kernel to detect and save the vertical lines in a jpg\n",
        "  image_1 = cv2.erode(img_bin, ver_kernel, iterations=3)\n",
        "  vertical_lines = cv2.dilate(image_1, ver_kernel, iterations=3)\n",
        "\n",
        "  #Use horizontal kernel to detect and save the horizontal lines in a jpg\n",
        "  image_2 = cv2.erode(img_bin, hor_kernel, iterations=3)\n",
        "  horizontal_lines = cv2.dilate(image_2, hor_kernel, iterations=3)\n",
        "\n",
        "  # Combine horizontal and vertical lines in a new third image, with both having same weight.\n",
        "  img_vh = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0.0)\n",
        "  #Eroding and thesholding the image\n",
        "  img_vh = cv2.erode(~img_vh, kernel, iterations=2)\n",
        "  if(conf.adaptive_filter):\n",
        "    img_vh = cv2.adaptiveThreshold(img_vh,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
        "  else:\n",
        "    thresh, img_vh = cv2.threshold(img_vh,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "  \n",
        "  return img_vh\n",
        "\n",
        "def Clean_Image(img, img_bin):\n",
        "  if(conf.threshold):\n",
        "    thresh, my_img = cv2.threshold(img,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)   \n",
        "  else:\n",
        "    my_img = img\n",
        "  \n",
        "  img_vh = Find_Lines(img_bin, kernel_factor = conf.kernel_factor_clean, morph_kernel = conf.morph_kernel_clean)\n",
        "\n",
        "  bitxor = cv2.bitwise_xor(my_img,img_vh)\n",
        "  bitnot = cv2.bitwise_not(bitxor)\n",
        "  \n",
        "  return bitnot\n",
        "\n",
        "def Arrange_Boxes(img, contours = None):\n",
        "\n",
        "  def sort_contours(cnts, method=\"left-to-right\"):\n",
        "      # initialize the reverse flag and sort index\n",
        "      reverse = False\n",
        "      i = 0\n",
        "      # handle if we need to sort in reverse\n",
        "      if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
        "          reverse = True\n",
        "      # handle if we are sorting against the y-coordinate rather than\n",
        "      # the x-coordinate of the bounding box\n",
        "      if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
        "          i = 1\n",
        "      # construct the list of bounding boxes and sort them from top to\n",
        "      # bottom\n",
        "      boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
        "      (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
        "      key=lambda b:b[1][i], reverse=reverse))\n",
        "      # return the list of sorted contours and bounding boxes\n",
        "      return (cnts, boundingBoxes)\n",
        "\n",
        "  # Sort all the contours by top to bottom.\n",
        "  contours, boundingBoxes = sort_contours(contours, method=\"top-to-bottom\")\n",
        "\n",
        "  #Creating a list of heights for all detected boxes\n",
        "  heights = [boundingBoxes[i][3] for i in range(len(boundingBoxes))]\n",
        "\n",
        "  #Get mean of heights\n",
        "  mean = np.mean(heights)\n",
        "\n",
        "  #Create list box to store all boxes in  \n",
        "  box = []\n",
        "  # Get position (x,y), width and height for every contour and show the contour on image\n",
        "  for c in contours:\n",
        "      x, y, w, h = cv2.boundingRect(c)\n",
        "      if (w<conf.max_width and h<conf.max_height and w>conf.min_width and h>conf.min_height):\n",
        "          image = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "          box.append([x,y,w,h])\n",
        "          \n",
        "  #Creating two lists to define row and column in which cell is located\n",
        "  row=[]\n",
        "  column=[]\n",
        "  j=0\n",
        "\n",
        "  #Sorting the boxes to their respective row and column\n",
        "  for i in range(len(box)):    \n",
        "          \n",
        "      if(i==0):\n",
        "          column.append(box[i])\n",
        "          previous=box[i]    \n",
        "      \n",
        "      else:\n",
        "          if(box[i][1]<=previous[1]+mean/2):\n",
        "              column.append(box[i])\n",
        "              previous=box[i]            \n",
        "              \n",
        "              if(i==len(box)-1):\n",
        "                  column = sorted(column, key=lambda b:b[0], reverse=True)\n",
        "                  row.append(column)        \n",
        "              \n",
        "          else:\n",
        "              column = sorted(column, key=lambda b:b[0], reverse=True)\n",
        "              row.append(column)\n",
        "              column=[]\n",
        "              previous = box[i]\n",
        "              column.append(box[i])\n",
        "\n",
        "  row[len(row)-1] = sorted(row[len(row)-1], key=lambda b:b[0], reverse=True)\n",
        "  if(conf.show_progress):        \n",
        "    print(\"Table Size: \", len(row),\"X\",len(row[0]))\n",
        "  \n",
        "  Nrows = len(row)\n",
        "  Ncols = max([len(r) for r in row])\n",
        "  print(\"Rows: \", Nrows, \" Cols: \", Ncols)\n",
        "  # Check if there are misaligned columns\n",
        "  col_centers = np.zeros((Nrows, Ncols))\n",
        "  for i in range(len(row)):\n",
        "    for j in range(len(row[i])):\n",
        "      col_centers[i, j] = (row[i][j][0] + row[i][j][2])/2 \n",
        "  \n",
        "  # print(col_centers.transpose())\n",
        "  better_boxes = [[None for j in range(Ncols)] for i in range(Nrows)]\n",
        "\n",
        "  header_widths = [r[2] for r in row[0]]\n",
        "  head_cent_limit = [[r[0] + 0.3*r[2], r[0] + 0.7*r[2]] for r in row[0]]\n",
        "  # print(head_cent_limit)\n",
        "  for i in range(Nrows):\n",
        "    r = row[i]\n",
        "    for b in r:\n",
        "      p = (b[0] + b[2]/2)\n",
        "      for j in range(Ncols):\n",
        "        if(p > head_cent_limit[j][0] and p < head_cent_limit[j][1]):\n",
        "          better_boxes[i][j] = b\n",
        "    \n",
        "  return better_boxes\n",
        "\n",
        "def DumpBoxes(image, boxes):\n",
        "    for i in range(len(boxes)):\n",
        "        for j in range(len(boxes[i])):\n",
        "            if(boxes[i][j] is None):\n",
        "                continue\n",
        "\n",
        "            y,x,w,h = boxes[i][j][0],boxes[i][j][1], boxes[i][j][2],boxes[i][j][3]\n",
        "            finalimg = image[x:x+h, y:y+w]\n",
        "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
        "            border = cv2.copyMakeBorder(finalimg,10,1,1,1, cv2.BORDER_CONSTANT,value=[255,255])\n",
        "            resizing = cv2.resize(border, None, fx=5, fy=5, interpolation=cv2.INTER_CUBIC)\n",
        "            # dilation = cv2.dilate(border, kernel,iterations=2)\n",
        "            # erosion = cv2.erode(dilation, kernel,iterations=1)\n",
        "            thresh, erosion = cv2.threshold(resizing,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "            if(i ==0 and j>=conf.rot_start and j<(len(boxes[i])-conf.rot_last)):\n",
        "                erosion = cv2.rotate(erosion, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "            # print(\"SmallImgs/img_{}_{}.png\".format(i, j))\n",
        "            cv2.imwrite(\"SmallImgs/img_{}_{}.png\".format(i, j),erosion)\n",
        "\n",
        "def OCR_Boxes(image,  boxes):\n",
        "    global arfont \n",
        "    global enfont\n",
        "\n",
        "    def clean_string(inp):\n",
        "        symbs = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789+-*|.\"\n",
        "        outp = \"\"\n",
        "        for c in inp:\n",
        "            if(symbs.find(c) != -1): outp += c\n",
        "        return outp\n",
        "\n",
        "    def clean_string_ara(inp):\n",
        "        symbs = \"دجحخهعغفقثصضطكمنتالبيسشظزوةىلارؤءئذإلإًَُأألأآلآْ \"\n",
        "        outp = \"\"\n",
        "        for c in inp:\n",
        "            if(symbs.find(c) != -1): outp += c\n",
        "        return outp\n",
        "\n",
        "    def rotate_box(im, scale = 1.0):\n",
        "        \"\"\"angle=270\n",
        "        (h, w) = im.shape[:2]\n",
        "\n",
        "        center = (w / 2, h / 2)\n",
        "\n",
        "        M = cv2.getRotationMatrix2D(center, angle, scale)\n",
        "        rotated = cv2.warpAffine(im, M, (w, h))\"\"\"\n",
        "\n",
        "        cv.Transpose(img,timg)\n",
        "        cv.Flip(timg,timg,flipMode=1)\n",
        "\n",
        "        return rotated\n",
        "\n",
        "    maxResult = 30\n",
        "    kx = 0\n",
        "    mix = 0\n",
        "    result = [[None for j in range(len(boxes[0]))] for i in range(len(boxes))]\n",
        "    for i in range(len(boxes)):\n",
        "        Ncols = 6\n",
        "        Nrows = math.ceil(len(boxes[i]) / Ncols)\n",
        "        \n",
        "        for j in range(len(boxes[i])):\n",
        "            if(boxes[i][j] is None):\n",
        "                continue\n",
        "\n",
        "            y,x,w,h = boxes[i][j][0],boxes[i][j][1], boxes[i][j][2],boxes[i][j][3]\n",
        "            finalimg = image[x:x+h, y:y+w]\n",
        "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
        "            border = cv2.copyMakeBorder(finalimg,2,2,2,2, cv2.BORDER_CONSTANT,value=[255,255])\n",
        "            resizing = cv2.resize(border, None, fx=5, fy=5, interpolation=cv2.INTER_CUBIC)\n",
        "            dilation = cv2.dilate(resizing, kernel,iterations=1)\n",
        "            erosion = cv2.erode(dilation, kernel,iterations=2)\n",
        "            thresh, erosion = cv2.threshold(erosion,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "            if(i ==0 and j>=conf.rot_start and j<(len(boxes[i])-conf.rot_last)):\n",
        "                erosion = cv2.rotate(erosion, cv2.ROTATE_90_CLOCKWISE)\n",
        "            #if(kx> maxResult):\n",
        "            #  continue\n",
        "            kx+=1\n",
        "            arabic_name = i >= conf.ara_row and j == conf.ara_col\n",
        "            arabic_header = i==0 and conf.header_arabic and not (j > conf.ara_col and j < (len(boxes[i])-conf.last_rows))\n",
        "            is_arabic = arabic_name or arabic_header\n",
        "            if(is_arabic):\n",
        "              erosion = cv2.resize(erosion, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_CUBIC)\n",
        "              out = pytesseract.image_to_string(erosion, lang = \"ara+eng\")\n",
        "              out = clean_string_ara(out)\n",
        "              #print(out)\n",
        "              if(len(out)<1):\n",
        "                  #print(\"RUNNEEER!\")\n",
        "                  erosion = cv2.resize(erosion, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "                  new_erosion = cv2.dilate(erosion, kernel,iterations=1)\n",
        "                  out = pytesseract.image_to_string(new_erosion, lang = \"ara+eng\")\n",
        "                  out = clean_string_ara(out)\n",
        "                  #plotting = plt.imshow(new_erosion,cmap='gray')\n",
        "                  ## plt.show()\n",
        "                  #print(x,y,w,h,\" || \",out)\n",
        "                  #mix += 1\n",
        "                  #if(mix==2):\n",
        "                  #   x = lo\n",
        "            else:\n",
        "              out = pytesseract.image_to_string(erosion)\n",
        "              out = clean_string(out)\n",
        "              if(len(out)<1):\n",
        "                  out = pytesseract.image_to_string(erosion, config=(\"-c tessedit\"\n",
        "                        \"_char_whitelist=abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789|.\"\n",
        "                        \" --psm 7\"\n",
        "                        \"-l osd\"\n",
        "                        \" \"))\n",
        "              out = clean_string(out)\n",
        "              if(len(out)<1):\n",
        "                  out = pytesseract.image_to_string(erosion, config=(\"-c tessedit\"\n",
        "                        \"_char_whitelist=abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789|.\"\n",
        "                        \" --psm 10\"\n",
        "                        \"-l osd\"\n",
        "                        \" \"))\n",
        "              out = clean_string(out)\n",
        "              if(len(out)<1):\n",
        "                  out = pytesseract.image_to_string(erosion, config=(\"-c tessedit\"\n",
        "                        \"_char_whitelist=abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789|.\"\n",
        "                        \" --psm 3\"\n",
        "                        \"-l osd\"\n",
        "                        \" \"))\n",
        "              out = clean_string(out)\n",
        "\n",
        "              out = fix_string(out,i,j,len(boxes[i])-conf.last_rows)\n",
        "\n",
        "            result[i][j] = out\n",
        "\n",
        "    return result\n",
        "\n",
        "def fix_string(inp, i, j, tot):\n",
        "      if(i >= conf.ara_row and j > conf.ara_col and j < tot):\n",
        "          if(inp == \"g\"):\n",
        "              inp = \"C\"\n",
        "          elif(inp == \"f-\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"f\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"fF\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"G\"):\n",
        "              inp = \"C\"\n",
        "          elif(inp == \"H+\"):\n",
        "              inp = \"B+\"\n",
        "          elif(inp == \"Bt\"):\n",
        "              inp = \"B+\"\n",
        "          elif(inp == \"At\"):\n",
        "              inp = \"A+\"\n",
        "          elif(inp == \"i.\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"t\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"7\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"vy\"):\n",
        "              inp = \"C\"\n",
        "          elif(inp == \"h\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"a\"):\n",
        "              inp = \"F*\"\n",
        "          elif(inp == \"a\"):###\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"i\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"I\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"4\"):\n",
        "              inp = \"A\"\n",
        "          elif(inp == \"HAE\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"o\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"oB\"):\n",
        "              inp = \"B\"\n",
        "          elif(inp == \"Fe\"):\n",
        "              inp = \"F*\"\n",
        "          elif(inp == \"p*\"):\n",
        "              inp = \"F*\"\n",
        "              \n",
        "          symbs = \"ABCDF+-*\"\n",
        "          outp = \"\"\n",
        "          for c in inp:\n",
        "              if(symbs.find(c) != -1): outp += c\n",
        "          return outp\n",
        "      return inp\n",
        "\n",
        "def Save_Excel(result, save_path):\n",
        "  def FormatString(s):\n",
        "    if isinstance(s, str):\n",
        "      try:\n",
        "        s.encode('unicode_escape').decode('utf-8')\n",
        "        return s\n",
        "      except:\n",
        "        return unidecode(s)\n",
        "    else:\n",
        "      return \"\"\n",
        "  \n",
        "  dataframe = pd.DataFrame(result)\n",
        "  dataframe = dataframe.applymap(FormatString)#lambda x:  if isinstance(x, str) else x)\n",
        "  #data = dataframe.style.set_properties(align=\"left\")\n",
        "  dataframe.to_excel(save_path, engine=conf.excel_engine)\n",
        "  print(\"Excel file successfully created, saved at\", save_path)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['Tahoma'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIwNe2Pdxro-"
      },
      "source": [
        "# **RecPDF**\n",
        "Recognizes each image in a PDF file, processes them one by one.\n",
        "\n",
        "**path:** path to the PDF file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ8ywbX3yNsy"
      },
      "source": [
        "import sys\n",
        "\n",
        "def RecPDF(path=\"\"):\n",
        "  with open(path, \"rb\") as file:\n",
        "      pdf = file.read()\n",
        "\n",
        "  img_counter = 0\n",
        "  pointer = 0\n",
        "  while True:\n",
        "      pointer = pdf.find(b\"stream\", pointer)\n",
        "      if pointer < 0:\n",
        "          break\n",
        "\n",
        "      x = pdf.find(b\"\\xff\\xd8\", pointer)\n",
        "      if x < 0:\n",
        "          pointer = pointer + 1\n",
        "          continue\n",
        "      else:\n",
        "          extension = \"jpg\"\n",
        "\n",
        "      limit = pdf.find(b\"endstream\", pointer)\n",
        "      if limit < 0:\n",
        "          break\n",
        "\n",
        "      y = pdf.find(b\"\\xff\\xd9\", pointer, limit) + 2\n",
        "\n",
        "      pointer = limit + 9\n",
        "      if y < 2:\n",
        "          continue        \n",
        "      \n",
        "      img = pdf[x:y]\n",
        "\n",
        "      img_counter = img_counter + 1\n",
        "\n",
        "      img_path = \"img_\" + str(img_counter) + \".\" + extension\n",
        "\n",
        "      with open(img_path, \"wb\") as jpgfile:\n",
        "          jpgfile.write(img)\n",
        "\n",
        "      RecImg(img_path, ocr=False, kernel_factor=260, morph_kernel=4, min_width =10, min_height=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMznfcYz3b_G"
      },
      "source": [
        "#**RecImg**\n",
        "Recognizes a table in image form, converts it to an Excel file.\n",
        "\n",
        "**path:** path to the input image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2mVSg9NvVGu"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image\n",
        "import pytesseract\n",
        "\n",
        "def RecImg(path=\"/content/sample.PNG\", excel_path = \"/content/test.xlsx\"):\n",
        "  #read your file\n",
        "  file= path\n",
        "  img = cv2.imread(file,0)\n",
        "\n",
        "  if(conf.show_progress):\n",
        "    print(\"ORIGINAL IMAGE\")\n",
        "    plotting = plt.imshow(img, cmap=\"gray\")\n",
        "    plt.show()\n",
        "\n",
        "  if(conf.adaptive_filter):\n",
        "    img_bin = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
        "  else:\n",
        "    thresh,img_bin = cv2.threshold(img,128,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU) \n",
        "  img_bin = 255-img_bin\n",
        "  \n",
        "  table = Cut_Table(img_bin, orig_img = img)\n",
        "  \n",
        "  if(conf.adaptive_filter):\n",
        "    table_bin = cv2.adaptiveThreshold(table,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
        "  else:\n",
        "    thresh,table_bin = cv2.threshold(table,128,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU) \n",
        "  table_bin = 255-table_bin\n",
        "\n",
        "  clean_table = Clean_Image(table, table_bin)\n",
        "\n",
        "  conts = Find_Contours(table_bin)\n",
        "  boxes = Arrange_Boxes(table, contours =conts)\n",
        "  \n",
        "  if(conf.ocr):\n",
        "    results = OCR_Boxes(clean_table, boxes)\n",
        "    Save_Excel(results, excel_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-BHcEPnzUbo"
      },
      "source": [
        "# **Utility Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmEvgWJAya6J"
      },
      "source": [
        "## **Cut Table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4BMxTQ7sCN0"
      },
      "source": [
        "def Cut_Table(img, orig_img = None):\n",
        "  img_vh = Find_Lines(img, conf.kernel_factor, conf.morph_kernel)\n",
        "  def find_largest_cont(in_img):\n",
        "    cnts, _ = cv2.findContours(in_img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:10]\n",
        "    table = None\n",
        "    i = 0\n",
        "    for c in cnts:\n",
        "      # approximate the contour\n",
        "      peri = cv2.arcLength(c, True)\n",
        "      approx = cv2.approxPolyDP(c, 0.015 * peri, True)\n",
        "\n",
        "      if len(approx) == 4 and i>conf.passes-1:\n",
        "        table = approx\n",
        "        break\n",
        "      else: print(\"PASS\")\n",
        "      i +=1\n",
        "    return table\n",
        "  \n",
        "  largest_cont = find_largest_cont(img_vh)\n",
        "\n",
        "  def crop_minAreaRect(img, screenCnt):\n",
        "    pts = screenCnt.reshape(4, 2)\n",
        "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
        "\n",
        "    s = pts.sum(axis = 1)\n",
        "    rect[0] = pts[np.argmin(s)]\n",
        "    rect[2] = pts[np.argmax(s)]\n",
        "\n",
        "    diff = np.diff(pts, axis = 1)\n",
        "    rect[1] = pts[np.argmin(diff)]\n",
        "    rect[3] = pts[np.argmax(diff)]\n",
        "    # multiply the rectangle by the original ratio\n",
        "    #rect *= ratio\n",
        "\n",
        "    (tl, tr, br, bl) = rect\n",
        "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
        "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
        "\n",
        "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
        "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
        "\n",
        "    maxWidth = max(int(widthA), int(widthB))\n",
        "    maxHeight = max(int(heightA), int(heightB))\n",
        "\n",
        "    dst = np.array([\n",
        "      [0, 0],\n",
        "      [maxWidth - 1, 0],\n",
        "      [maxWidth - 1, maxHeight - 1],\n",
        "      [0, maxHeight - 1]], dtype = \"float32\")\n",
        "\n",
        "    M = cv2.getPerspectiveTransform(rect, dst)\n",
        "    warp = cv2.warpPerspective(img, M, (maxWidth, maxHeight))\n",
        "    return warp\n",
        "  table_img = crop_minAreaRect(orig_img, largest_cont)\n",
        "  if(conf.show_progress):\n",
        "    print(\"CROPPED TABLE\")\n",
        "    plotting = plt.imshow(table_img,cmap='gray')\n",
        "    plt.show()\n",
        "  return table_img"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qoSLSg5yiVv"
      },
      "source": [
        "## **Find Contours**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2siX6zhrJa6"
      },
      "source": [
        "def Find_Contours(img):\n",
        "  img_vh = Find_Lines(img, conf.kernel_factor, conf.morph_kernel)\n",
        "  contours, hierarchy = cv2.findContours(img_vh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  return contours"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhMZmx9lylIT"
      },
      "source": [
        "## **Find Lines**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ1MCFBTqfAY"
      },
      "source": [
        "def Find_Lines(img_bin, kernel_factor = 300, morph_kernel=1):\n",
        "  # countcol(width) of kernel as 100th of total width\n",
        "  kernel_len = np.array(img_bin).shape[1]//kernel_factor\n",
        "  # Defining a vertical kernel to detect all vertical lines of image \n",
        "  ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_len))\n",
        "  # Defining a horizontal kernel to detect all horizontal lines of image\n",
        "  hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_len, 1))\n",
        "  # A kernel of 2x2\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (morph_kernel, morph_kernel))\n",
        "\n",
        "  #Use vertical kernel to detect and save the vertical lines in a jpg\n",
        "  image_1 = cv2.erode(img_bin, ver_kernel, iterations=3)\n",
        "  vertical_lines = cv2.dilate(image_1, ver_kernel, iterations=3)\n",
        "\n",
        "  #Use horizontal kernel to detect and save the horizontal lines in a jpg\n",
        "  image_2 = cv2.erode(img_bin, hor_kernel, iterations=3)\n",
        "  horizontal_lines = cv2.dilate(image_2, hor_kernel, iterations=3)\n",
        "\n",
        "  # Combine horizontal and vertical lines in a new third image, with both having same weight.\n",
        "  img_vh = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0.0)\n",
        "  #Eroding and thesholding the image\n",
        "  img_vh = cv2.erode(~img_vh, kernel, iterations=2)\n",
        "  if(conf.adaptive_filter):\n",
        "    img_vh = cv2.adaptiveThreshold(img_vh,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
        "  else:\n",
        "    thresh, img_vh = cv2.threshold(img_vh,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "  \n",
        "  return img_vh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDOtRHE2yoHr"
      },
      "source": [
        "## **Clean Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwSoA9-PqQ8m"
      },
      "source": [
        "def Clean_Image(img, img_bin):\n",
        "  if(conf.threshold):\n",
        "    thresh, my_img = cv2.threshold(img,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)   \n",
        "  else:\n",
        "    my_img = img\n",
        "  \n",
        "  img_vh = Find_Lines(img_bin, kernel_factor = conf.kernel_factor_clean, morph_kernel = conf.morph_kernel_clean)\n",
        "\n",
        "  bitxor = cv2.bitwise_xor(my_img,img_vh)\n",
        "  bitnot = cv2.bitwise_not(bitxor)\n",
        "  \n",
        "  if(conf.show_progress):\n",
        "    print(\"CLEAN IMAGE\")\n",
        "    plotting = plt.imshow(bitnot,cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "  return bitnot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJvze67Ayrbx"
      },
      "source": [
        "## **Arrange Boxes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spXJDSS1pzI8"
      },
      "source": [
        "def Arrange_Boxes(img, contours = None):\n",
        "\n",
        "  def sort_contours(cnts, method=\"left-to-right\"):\n",
        "      # initialize the reverse flag and sort index\n",
        "      reverse = False\n",
        "      i = 0\n",
        "      # handle if we need to sort in reverse\n",
        "      if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
        "          reverse = True\n",
        "      # handle if we are sorting against the y-coordinate rather than\n",
        "      # the x-coordinate of the bounding box\n",
        "      if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
        "          i = 1\n",
        "      # construct the list of bounding boxes and sort them from top to\n",
        "      # bottom\n",
        "      boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
        "      (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
        "      key=lambda b:b[1][i], reverse=reverse))\n",
        "      # return the list of sorted contours and bounding boxes\n",
        "      return (cnts, boundingBoxes)\n",
        "\n",
        "  # Sort all the contours by top to bottom.\n",
        "  contours, boundingBoxes = sort_contours(contours, method=\"top-to-bottom\")\n",
        "\n",
        "  #Creating a list of heights for all detected boxes\n",
        "  heights = [boundingBoxes[i][3] for i in range(len(boundingBoxes))]\n",
        "\n",
        "  #Get mean of heights\n",
        "  mean = np.mean(heights)\n",
        "\n",
        "  #Create list box to store all boxes in  \n",
        "  box = []\n",
        "  # Get position (x,y), width and height for every contour and show the contour on image\n",
        "  for c in contours:\n",
        "      x, y, w, h = cv2.boundingRect(c)\n",
        "      if (w<conf.max_width and h<conf.max_height and w>conf.min_width and h>conf.min_height):\n",
        "          image = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "          box.append([x,y,w,h])\n",
        "          \n",
        "\n",
        "  if(conf.show_progress):      \n",
        "    print(\"EXTRACTED BOXES\")  \n",
        "    plotting = plt.imshow(image,cmap='GnBu_r')\n",
        "    plt.show()\n",
        "  #Creating two lists to define row and column in which cell is located\n",
        "  row=[]\n",
        "  column=[]\n",
        "  j=0\n",
        "\n",
        "  #Sorting the boxes to their respective row and column\n",
        "  for i in range(len(box)):    \n",
        "          \n",
        "      if(i==0):\n",
        "          column.append(box[i])\n",
        "          previous=box[i]    \n",
        "      \n",
        "      else:\n",
        "          if(box[i][1]<=previous[1]+mean/2):\n",
        "              column.append(box[i])\n",
        "              previous=box[i]            \n",
        "              \n",
        "              if(i==len(box)-1):\n",
        "                  column = sorted(column, key=lambda b:b[0], reverse=True)\n",
        "                  row.append(column)        \n",
        "              \n",
        "          else:\n",
        "              column = sorted(column, key=lambda b:b[0], reverse=True)\n",
        "              row.append(column)\n",
        "              column=[]\n",
        "              previous = box[i]\n",
        "              column.append(box[i])\n",
        "  \n",
        "  row[len(row)-1] = sorted(row[len(row)-1], key=lambda b:b[0], reverse=True)\n",
        "  if(conf.show_progress):        \n",
        "    print(\"Table Size: \", len(row),\"X\",len(row[0]))\n",
        "  return row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmndbB95yuFo"
      },
      "source": [
        "## **OCR Boxes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc0bkmH_or9O"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def OCR_Boxes(image,  boxes):\n",
        "  def clean_string(inp):\n",
        "      symbs = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789+-*|.\"\n",
        "      outp = \"\"\n",
        "      for c in inp:\n",
        "          if(symbs.find(c) != -1): outp += c\n",
        "      return outp\n",
        "\n",
        "  def clean_string_ara(inp):\n",
        "      symbs = \"دجحخهعغفقثصضطكمنتالبيسشظزوةىلارؤءئذإلإًَُأألأآلآْ \"\n",
        "      outp = \"\"\n",
        "      for c in inp:\n",
        "          if(symbs.find(c) != -1): outp += c\n",
        "      return outp\n",
        "\n",
        "  def rotate_box(im, scale = 1.0):\n",
        "    \"\"\"angle=270\n",
        "    (h, w) = im.shape[:2]\n",
        "\n",
        "    center = (w / 2, h / 2)\n",
        "\n",
        "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
        "    rotated = cv2.warpAffine(im, M, (w, h))\"\"\"\n",
        "\n",
        "    cv.Transpose(img,timg)\n",
        "    cv.Flip(timg,timg,flipMode=1)\n",
        "\n",
        "    return rotated\n",
        "\n",
        "  maxResult = 30\n",
        "  kx = 0\n",
        "  mix = 0\n",
        "  result = []\n",
        "  for i in range(len(boxes)):\n",
        "      result.append([])\n",
        "      for j in range(len(boxes[i])):\n",
        "          y,x,w,h = boxes[i][j][0],boxes[i][j][1], boxes[i][j][2],boxes[i][j][3]\n",
        "          finalimg = image[x:x+h, y:y+w]\n",
        "          kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
        "          border = cv2.copyMakeBorder(finalimg,2,2,2,2, cv2.BORDER_CONSTANT,value=[255,255])\n",
        "          resizing = cv2.resize(border, None, fx=5, fy=5, interpolation=cv2.INTER_CUBIC)\n",
        "          dilation = cv2.dilate(resizing, kernel,iterations=1)\n",
        "          erosion = cv2.erode(dilation, kernel,iterations=2)\n",
        "          thresh, erosion = cv2.threshold(erosion,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "          if(i ==0 and j>=conf.rot_start and j<(len(boxes[i])-conf.rot_last)):\n",
        "              erosion = cv2.rotate(erosion, cv2.ROTATE_90_CLOCKWISE)\n",
        "          #if(kx> maxResult):\n",
        "          #  continue\n",
        "          kx+=1\n",
        "          arabic_name = i >= conf.ara_row and j == conf.ara_col\n",
        "          arabic_header = i==0 and conf.header_arabic and not (j > conf.ara_col and j < (len(boxes[i])-conf.last_rows))\n",
        "          is_arabic = arabic_name or arabic_header\n",
        "          if(is_arabic):\n",
        "              erosion = cv2.resize(erosion, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_CUBIC)\n",
        "              out = pytesseract.image_to_string(erosion, lang = \"ara\")\n",
        "              out = clean_string_ara(out)\n",
        "              #print(out)\n",
        "              if(len(out)<1):\n",
        "                  #print(\"RUNNEEER!\")\n",
        "                  erosion = cv2.resize(erosion, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "                  new_erosion = cv2.dilate(erosion, kernel,iterations=1)\n",
        "                  out = pytesseract.image_to_string(new_erosion, lang = \"ara\")\n",
        "                  out = clean_string_ara(out)\n",
        "                  #plotting = plt.imshow(new_erosion,cmap='gray')\n",
        "                  #plt.show()\n",
        "                  #print(x,y,w,h,\" || \",out)\n",
        "                  #mix += 1\n",
        "                  #if(mix==2):\n",
        "                  #   x = lo\n",
        "          else:\n",
        "              out = pytesseract.image_to_string(erosion)\n",
        "              out = clean_string(out)\n",
        "              if(len(out)<1):\n",
        "                  out = pytesseract.image_to_string(erosion, config=(\"-c tessedit\"\n",
        "                        \"_char_whitelist=abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789|.\"\n",
        "                        \" --psm 7\"\n",
        "                        \"-l osd\"\n",
        "                        \" \"))\n",
        "              out = clean_string(out)\n",
        "              if(len(out)<1):\n",
        "                  out = pytesseract.image_to_string(erosion, config=(\"-c tessedit\"\n",
        "                        \"_char_whitelist=abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789|.\"\n",
        "                        \" --psm 10\"\n",
        "                        \"-l osd\"\n",
        "                        \" \"))\n",
        "              out = clean_string(out)\n",
        "              if(len(out)<1):\n",
        "                  out = pytesseract.image_to_string(erosion, config=(\"-c tessedit\"\n",
        "                        \"_char_whitelist=abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789|.\"\n",
        "                        \" --psm 3\"\n",
        "                        \"-l osd\"\n",
        "                        \" \"))\n",
        "              out = clean_string(out)\n",
        "\n",
        "              out = fix_string(out,i,j,len(boxes[i])-conf.last_rows)\n",
        "\n",
        "          if(conf.show_progress):\n",
        "              plotting = plt.imshow(erosion,cmap='gray')\n",
        "              plt.show()\n",
        "              print(x,y,w,h,\" || \",out)\n",
        "          \n",
        "          result[i].append(out)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wyM1MyXdKT3"
      },
      "source": [
        "def fix_string(inp, i, j, tot):\n",
        "      if(i >= conf.ara_row and j > conf.ara_col and j < tot):\n",
        "          if(inp == \"g\"):\n",
        "              inp = \"C\"\n",
        "          elif(inp == \"f-\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"f\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"fF\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"G\"):\n",
        "              inp = \"C\"\n",
        "          elif(inp == \"H+\"):\n",
        "              inp = \"B+\"\n",
        "          elif(inp == \"Bt\"):\n",
        "              inp = \"B+\"\n",
        "          elif(inp == \"At\"):\n",
        "              inp = \"A+\"\n",
        "          elif(inp == \"i.\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"t\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"7\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"vy\"):\n",
        "              inp = \"C\"\n",
        "          elif(inp == \"h\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"a\"):\n",
        "              inp = \"F*\"\n",
        "          elif(inp == \"a\"):###\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"i\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"I\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"4\"):\n",
        "              inp = \"A\"\n",
        "          elif(inp == \"HAE\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"o\"):\n",
        "              inp = \"F\"\n",
        "          elif(inp == \"oB\"):\n",
        "              inp = \"B\"\n",
        "          elif(inp == \"Fe\"):\n",
        "              inp = \"F*\"\n",
        "          elif(inp == \"p*\"):\n",
        "              inp = \"F*\"\n",
        "              \n",
        "          symbs = \"ABCDF+-*\"\n",
        "          outp = \"\"\n",
        "          for c in inp:\n",
        "              if(symbs.find(c) != -1): outp += c\n",
        "          return outp\n",
        "      return inp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8--ngH4Lywuh"
      },
      "source": [
        "## **Save Excel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZFQ6l0CwsOT"
      },
      "source": [
        "def Save_Excel(result, save_path):\n",
        "  def FormatString(s):\n",
        "    if isinstance(s, str):\n",
        "      try:\n",
        "        s.encode('unicode_escape').decode('utf-8')\n",
        "        return s\n",
        "      except:\n",
        "        return unidecode(s)\n",
        "    else:\n",
        "      return \"\"\n",
        "  \n",
        "  dataframe = pd.DataFrame(result)\n",
        "  dataframe = dataframe.applymap(FormatString)#lambda x:  if isinstance(x, str) else x)\n",
        "  #data = dataframe.style.set_properties(align=\"left\")\n",
        "  dataframe.to_excel(save_path, engine=conf.excel_engine)\n",
        "  print(\"Excel file successfully created, saved at\", save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3d1523RC_7-",
        "outputId": "5e02e1ba-d444-4a94-b214-8b43347cdc31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "        \n",
        "  if(show_progress):          \n",
        "    print(len(column))\n",
        "    print(len(row))\n",
        "\n",
        "  #calculating maximum number of cells\n",
        "  max_countcol = 0\n",
        "  for i in range(len(row)):\n",
        "      countcol = len(row[i])\n",
        "      if countcol > max_countcol:\n",
        "          max_countcol = countcol\n",
        "\n",
        "  countcol = max_countcol\n",
        "\n",
        "  #Retrieving the center of each column\n",
        "  center = [int(row[i][j][0]+row[i][j][2]/2) for j in range(len(row[i])) if row[0]]\n",
        "\n",
        "  center=np.array(center)\n",
        "  center.sort()\n",
        "  #if(show_progress):\n",
        "  #  print(center)\n",
        "\n",
        "  #Regarding the distance to the columns center, the boxes are arranged in respective order\n",
        "\n",
        "  finalboxes = []\n",
        "  #my_max = 300000000\n",
        "  #how_many = 1\n",
        "  return\n",
        "  if(ocr):\n",
        "    #from every single image-based cell/box the strings are extracted via pytesseract and stored in a list\n",
        "    outer=[]\n",
        "    for i in range(len(finalboxes)):\n",
        "        for j in range(len(finalboxes[i])):\n",
        "            inner=''\n",
        "            if(len(finalboxes[i][j])==0):\n",
        "                outer.append(' ')\n",
        "            else:\n",
        "                for k in range(len(finalboxes[i][j])):\n",
        "                    y,x,w,h = finalboxes[i][j][k][0],finalboxes[i][j][k][1], finalboxes[i][j][k][2],finalboxes[i][j][k][3]\n",
        "                    finalimg = bitnot[x:x+h, y:y+w]\n",
        "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))\n",
        "                    border = cv2.copyMakeBorder(finalimg,2,2,2,2, cv2.BORDER_CONSTANT,value=[255,255])\n",
        "                    resizing = cv2.resize(border, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "                    dilation = cv2.dilate(resizing, kernel,iterations=1)\n",
        "                    erosion = cv2.erode(dilation, kernel,iterations=2)\n",
        "                    \n",
        "                    #out = pytesseract.image_to_string(erosion)\n",
        "                    #if(len(out)==0):\n",
        "                    out = pytesseract.image_to_string(erosion, config='--psm 3')\n",
        "                    if(show_progress):\n",
        "                      print(x,y,w,h,out)\n",
        "                    inner = inner +\" \"+ out\n",
        "                outer.append(inner)\n",
        "\n",
        "    #Creating a dataframe of the generated OCR list\n",
        "    arr = np.array(outer)\n",
        "    dataframe = pd.DataFrame(arr.reshape(len(row), countcol))\n",
        "    print(dataframe)\n",
        "    data = dataframe.style.set_properties(align=\"left\")\n",
        "    #Converting it in a excel-file\n",
        "    data.to_excel(\"/content/test.xlsx\", engine=excel_engine)\n",
        "\n",
        "    def Clean_Image(img, img_bin):\n",
        "  if(conf.threshold):\n",
        "    thresh, my_img = cv2.threshold(my_img,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)   \n",
        "  else:\n",
        "    my_img = img\n",
        "  \n",
        "  img_vh = Find_Lines(img_bin, kernel_factor = conf.kernel_factor_clean, morph_kernel = conf.morph_kernel_clean)\n",
        "\n",
        "  bitand = cv2.bitwise_and(my_img, cv2.bitwise_not(img_vh))\n",
        "  bitxor = cv2.bitwise_xor(cv2.bitwise_not(my_img), bitand)\n",
        "  bitnot = cv2.bitwise_not(bitxor)\n",
        "  \n",
        "  if(conf.show_progress):\n",
        "    print(\"AND IMAGE\")\n",
        "    plotting = plt.imshow(bitand,cmap='gray')\n",
        "    plt.show()\n",
        "    print(\"MY IMAGE\")\n",
        "    plotting = plt.imshow(cv2.bitwise_not(my_img),cmap='gray')\n",
        "    plt.show()\n",
        "    print(\"XOR IMAGE\")\n",
        "    plotting = plt.imshow(bitxor,cmap='gray')\n",
        "    plt.show()\n",
        "    print(\"CLEAN IMAGE\")\n",
        "    plotting = plt.imshow(bitnot,cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "  return bitnot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-59ba57537e8e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    if(show_progress):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioxFKsRASmxM"
      },
      "source": [
        "ui = \"5431\"\n",
        "\n",
        "if(ui.find(\"7\") != -1):\n",
        "  print(\"dfd\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0B_k9PBStjC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}